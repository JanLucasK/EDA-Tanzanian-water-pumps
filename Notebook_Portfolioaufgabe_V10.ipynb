{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4925a236",
   "metadata": {
    "id": "4925a236"
   },
   "source": [
    "<a id=’Business_Understanding’></a>\n",
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab09ec4",
   "metadata": {
    "id": "3ab09ec4"
   },
   "source": [
    "We have been tasked with developing a machine learning model for predicting the functionality of a water point (i.e., well) in Tanzania. Our data set was given to us from an unnamed source, and the aim of the project is unclear to us:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbaf3ab",
   "metadata": {
    "id": "7dbaf3ab"
   },
   "source": [
    "<a id=’Installation_and_Imports’></a>\n",
    "### Installation and Imports\n",
    "\n",
    "Before getting to work with the data, we begin by first importing all of the packages required throughout the notebook. This is done at the beginning of the notebook so that we can keep track of what packages we are using, as well as what variables we have assigned to the packages for method calls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e598407",
   "metadata": {
    "id": "8e598407"
   },
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "# !pip install lazypredict\n",
    "# !pip install imblearn\n",
    "# !pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40382d2a",
   "metadata": {
    "id": "40382d2a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statistics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b116f8",
   "metadata": {
    "id": "25b116f8"
   },
   "source": [
    "<a id=’Data_Understanding’></a>\n",
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13efcef6",
   "metadata": {
    "id": "13efcef6"
   },
   "source": [
    "Before we analyse and model our data, we must first understand what exactly it is that our data represents. This information we have collected in a Data Dictionary. Having completed this step we will then seek to develop an idea of the basic shape and properties of the data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c400ff",
   "metadata": {
    "id": "09c400ff"
   },
   "source": [
    "### Data dictionary\n",
    "\n",
    "amount_tsh - Total static head (amount water available to waterpoint)\n",
    "\n",
    "date_recorded - The date the row was entered\n",
    "\n",
    "funder - Who funded the well\n",
    "\n",
    "gps_height - Altitude of the well\n",
    "\n",
    "installer - Organization that installed the well\n",
    "\n",
    "longitude - GPS coordinate\n",
    "\n",
    "latitude - GPS coordinate\n",
    "\n",
    "wpt_name - Name of the waterpoint if there is one\n",
    "\n",
    "num_private -\n",
    "\n",
    "basin - Geographic water basin\n",
    "\n",
    "subvillage - Geographic location\n",
    "\n",
    "region - Geographic location\n",
    "\n",
    "region_code - Geographic location (coded)\n",
    "\n",
    "district_code - Geographic location (coded)\n",
    "\n",
    "lga - Geographic location\n",
    "\n",
    "ward - Geographic location\n",
    "\n",
    "population - Population around the well\n",
    "\n",
    "public_meeting - True/False\n",
    "\n",
    "recorded_by - Group entering this row of data\n",
    "\n",
    "scheme_management - Who operates the waterpoint\n",
    "\n",
    "scheme_name - Who operates the waterpoint\n",
    "\n",
    "permit - If the waterpoint is permitted\n",
    "\n",
    "construction_year - Year the waterpoint was constructed\n",
    "\n",
    "extraction_type - The kind of extraction the waterpoint uses\n",
    "\n",
    "extraction_type_group - The kind of extraction the waterpoint uses\n",
    "\n",
    "extraction_type_class - The kind of extraction the waterpoint uses\n",
    "\n",
    "management - How the waterpoint is managed\n",
    "\n",
    "management_group - How the waterpoint is managed\n",
    "\n",
    "payment - What the water costs\n",
    "\n",
    "payment_type - What the water costs\n",
    "\n",
    "water_quality - The quality of the water\n",
    "\n",
    "quality_group - The quality of the water\n",
    "\n",
    "quantity - The quantity of water\n",
    "\n",
    "quantity_group - The quantity of water\n",
    "\n",
    "source - The source of the water\n",
    "\n",
    "source_type - The source of the water\n",
    "\n",
    "source_class - The source of the water\n",
    "\n",
    "waterpoint_type - The kind of waterpoint\n",
    "\n",
    "waterpoint_type_group - The kind of waterpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816c7a4e",
   "metadata": {
    "id": "816c7a4e"
   },
   "source": [
    "### Data Shape and Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f9dbe3",
   "metadata": {
    "id": "88f9dbe3"
   },
   "outputs": [],
   "source": [
    "pump_train = pd.read_csv('pump_train.csv')\n",
    "pump_test = pd.read_csv('pump_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895d0f14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "895d0f14",
    "outputId": "35de9ed1-0984-474d-936f-9ba9b61d3809"
   },
   "outputs": [],
   "source": [
    "pump_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bfbc5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19bfbc5a",
    "outputId": "70427dc9-a9df-43a5-b168-07cf372aa304"
   },
   "outputs": [],
   "source": [
    "pump_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea22be",
   "metadata": {
    "id": "33ea22be"
   },
   "source": [
    "Our training data consists of 50490 data entries with attributes spread over 41 variables. \n",
    "\n",
    "Our training data consists of 8910 data entries with attributes spread over 41 variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a03ec7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4a03ec7d",
    "outputId": "96b9115a-5a5f-43a0-b78b-5b2c530c5071",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pump_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a5da6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "971a5da6",
    "outputId": "7bf1b4e6-d5b6-4da0-f848-fc53391b1f63",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pump_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0155a12",
   "metadata": {
    "id": "c0155a12"
   },
   "source": [
    "The data types for our variables span from numerical values (int64 and float64) to what appears to be categorical values (object). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48824934",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48824934",
    "outputId": "072ec39a-1e75-43d7-e0c9-ea0728a49a9f"
   },
   "outputs": [],
   "source": [
    "pump_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f93ac6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4f93ac6",
    "outputId": "6a8af51d-d79a-4a95-d004-97930d55d296"
   },
   "outputs": [],
   "source": [
    "pump_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88b2258",
   "metadata": {
    "id": "d88b2258"
   },
   "source": [
    "Unfortunately, we have a lot of null values in our data set. This will need to be taken into consideration in the data analysis and eventually rectified in data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d639c2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d639c2d",
    "outputId": "23ffaa4f-2ff7-4099-c4ae-8e5b72f4b36f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pump_train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e559ae",
   "metadata": {
    "id": "64e559ae"
   },
   "source": [
    "### Data shape and properties summary\n",
    "\n",
    "We have been tasked with developing a machine learning model to predict the value of the variable 'status_group', which variable can carry three possible values: 'non_functional', 'functional needs repair', and 'functional'. Our training data set is composed of 50490 observations cast over 41 variables. This means that we have 40 features that we can take into consideration when training our model. Whether or not it makes sense to include all of these features in our training is a matter to be considered later the data analysis and data preparation phases. \n",
    "\n",
    "Unfortunately, not all of our observations are complete. Indeed, 7 out of our 40 features have missing values. This will need to be taken into consideration during the data visualisation phase, and then later rectified in the data preparation phase. \n",
    "\n",
    "Also important to take note of here are the data types of the various features. More than half of our features carry the data type 'object'. This is problematic, as many machine learning models have difficulties with non-numerical values. This will also need to be addressed during the data preparation phase. \n",
    "\n",
    "Finally, those features which are expressed numerically, either as an int value or a float value, are scaled differently. If these values are feed directly into a training algorithim then they could lead to skewed results, and as such, this must also be addressed during the data preparation phase.   \n",
    "\n",
    "We proceed now to data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7674ed",
   "metadata": {
    "id": "ff7674ed"
   },
   "source": [
    "<a id=’Data_Analysis’></a>\n",
    "\n",
    "# Data Analysis\n",
    "\n",
    "The following section is broken into the following three sub-sections: numerical features, categorical features, and target variable.\n",
    "\n",
    "A mixture of statistical analyses and data visualisations should provide us with a better understanding of the data set that we are working with. This will, moreover, provide us with a set of action points for the data preparation phase, as well as important insights for the modelling phase. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c08fa7",
   "metadata": {
    "id": "64c08fa7"
   },
   "source": [
    "## Numerical Features\n",
    "\n",
    "Let us now take a closer look at our attributes with numerical values, i.e., int or float data types. \n",
    "First we will call up some basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94076423",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "94076423",
    "outputId": "d18c5c1b-7d5c-40bd-f00a-137e81e4a8f1"
   },
   "outputs": [],
   "source": [
    "pump_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2034a9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 725
    },
    "id": "f2034a9a",
    "outputId": "cd5e5c39-b0f9-459d-9c9f-e4338378aec9"
   },
   "outputs": [],
   "source": [
    "pump_train.hist(bins=50, density=False, figsize=(12,10))  # density=False would make counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37acb35",
   "metadata": {
    "id": "d37acb35"
   },
   "source": [
    "Id obviously tells us nothing about any individual water point and we can accordingly disregard it for the purposes of data analysis. \n",
    "\n",
    "The attribute 'amount_tsh' (amount of water available at water point) is, however, worthy of further consideration. From the statistical analysis we know that many of the water points have no water in them. Whether or not these observations are veridical is questionable. \n",
    "\n",
    "The 'gps_height' attribute refers to the altitude above sea level of the water point. This is also relevant to our analyses. The histogramm shows that the vast majority of water points are clustered around sea level, but there is also no shortage of water points located at higher altitudes up to the highest at 2770 metres above sea level. \n",
    "\n",
    "For the attributes 'longitude' and 'latitude' we require more advanced visualisations that place water points on a map for them to be of more assistance. We will leave this to later. \n",
    "\n",
    "We do not have a data dictionary entry for the attribute 'num_private' and we will accordingly leave this attribute out of our analysis. \n",
    "\n",
    "The attributes 'region code' and 'district code' require further information to be interpreted. It is conceivable that this could be done by caclculating the correlation scores for 'region' and 'region_code' and 'district code'. Whether or not this could lead to any concrete inights is something to be considered later. \n",
    "\n",
    "The attribute 'population' is relevant as it gives us an indication of how many people the waterpoint is servicing. The vast majority of water points have a very small population value. The average is ~ 180. This value is however likely skewed on account of the presence of outliers.  \n",
    "\n",
    "The attribute 'construction_year' is also important. Unfortuantely, our data here is likely corrupt, as many of our data entries have the value 0 for this variable. As such, our statistics and histogramm above are also likely inaccurate. We will need to consider this in more detail in the sequel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e8ca8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "id": "368e8ca8",
    "outputId": "ac42b799-52d2-4b32-b231-6e0e03a1c54f"
   },
   "outputs": [],
   "source": [
    "numeric_pump = pump_train.select_dtypes(include=[np.number])\n",
    "\n",
    "corr = numeric_pump._get_numeric_data().corr()\n",
    "\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "heatmap = sns.heatmap(corr, mask=mask, cmap=cmap, center=0.0,\n",
    "                      vmax = 1, square=True, linewidths=.5, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d570200",
   "metadata": {
    "id": "2d570200"
   },
   "source": [
    "Of interest in the above correlation matrix are the scores for 'construction_year'. We see that there is a strong relation between 'gps_height', 'population' and 'longitude'. Any number of hypotheses could be built on top of these relaiton scores. We  will save that discussion for later.  \n",
    "\n",
    "The fact that 'region_code' correlates with 'district_code' is both unsurprising and irrelevant. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071357ce",
   "metadata": {
    "id": "071357ce"
   },
   "source": [
    "### Amount of Water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c90e6c3",
   "metadata": {
    "id": "3c90e6c3",
    "outputId": "4c01aa5e-922a-4a12-e01f-17d78636b606"
   },
   "outputs": [],
   "source": [
    "empty_wp = len(pump_train[(pump_train.amount_tsh > 0)])\n",
    "print('There are ' + str(empty_wp) + ' non-empty water points in our data set.')\n",
    "print('This number reflects ' + str(empty_wp / len(pump_train)) + '% of the water points in our data set.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab0b460",
   "metadata": {
    "id": "0ab0b460"
   },
   "source": [
    "This number is seemingly low. Roughly 70% of our data set is composed of water points that don't actually have any water in them. This also raises an important question relating to the data dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b306543e",
   "metadata": {
    "id": "b306543e",
    "outputId": "0133c104-b782-4343-e5c4-cf9f95477574"
   },
   "outputs": [],
   "source": [
    "functional_wp = len(pump_train[(pump_train.status_group == 'functional')])\n",
    "functional_np_wp = len(pump_train[(pump_train.status_group == 'functional needs repair')])\n",
    "print(functional_wp + functional_np_wp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a0e6c6",
   "metadata": {
    "id": "32a0e6c6"
   },
   "source": [
    "We have 31113 functional or semi-functional water points in our data, but we have only 15060 non-empty waterpoints. If our data is not corrupt, this means that a functional water point is not necessarily a water point that can actually deliver water. Presumably, a functional water point is thus defined as a water point that is in mechanical order, but which may or may not have any water in it. This is important to keep in mind as we move forward.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd32fb9",
   "metadata": {
    "id": "6cd32fb9",
    "outputId": "ed02dd2a-f374-49d3-8ea9-89cbd9704ad9"
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(pump_train, hue='status_group', height=6)\n",
    "g.map(sns.histplot,'quantity_group',edgecolor=\"w\").add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033767ab",
   "metadata": {},
   "source": [
    "Furthermore, one can see that the feature quantity_group \"dry\" only contains about 5000 wells, which are dry. This does not correspond to the number of wells with no water. This means that most of the values ​​that correspond to 0 stand for missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1a76d4",
   "metadata": {
    "id": "bd1a76d4"
   },
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf4eca3",
   "metadata": {
    "id": "bbf4eca3",
    "outputId": "17d661cd-4f1b-4f5d-e8f8-d1ca016bd2c1"
   },
   "outputs": [],
   "source": [
    "pump_train['population'].loc[pump_train['population']].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af37ee3",
   "metadata": {
    "id": "8af37ee3"
   },
   "source": [
    "The above histogramm isn't particularly helpful. Let's try again with a box plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3031269",
   "metadata": {
    "id": "a3031269",
    "outputId": "be3fb4c6-0a03-40bf-8ef5-822ce7abcbb4"
   },
   "outputs": [],
   "source": [
    "pop_bp = sns.boxplot(x=pump_train[\"population\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e140a5c1",
   "metadata": {
    "id": "e140a5c1"
   },
   "source": [
    "Although the boxplot above is difficult to read, we can see still make out two possible problems in the 'population' attribute. \n",
    "1. The presence of a large number of outliers. This is problematic as some machine learning models have difficulties with outliers.  \n",
    "2. Data entries with a population of 0. This is problematic, as it could indicate some form of data corruption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf4250d",
   "metadata": {
    "id": "dbf4250d",
    "outputId": "9e0549aa-ec9a-499a-fae9-f9c77ded7c6c"
   },
   "outputs": [],
   "source": [
    "pop_0 = pump_train.loc[(pump_train.population == 0)]\n",
    "print(str(len(pop_0)) + ' water points have a population of 0.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5e7513",
   "metadata": {
    "id": "4c5e7513",
    "outputId": "dcd47584-2f5a-4778-add1-5b2d2cadb7e0"
   },
   "outputs": [],
   "source": [
    "pop_1 = pump_train.loc[(pump_train.population == 1)]\n",
    "print(str(len(pop_1)) + ' water points have a population of 1.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd86392",
   "metadata": {
    "id": "7cd86392",
    "outputId": "9ed3f97a-772b-4840-b860-2f950635f407"
   },
   "outputs": [],
   "source": [
    "print(str(len(pop_0) + len(pop_1)) + ' water points have a population of either 0 or 1. That is approximately half of our data set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c324f",
   "metadata": {
    "id": "ed8c324f"
   },
   "source": [
    "Let us see what our data looks like if we remove data entries with a population of 0 or 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1690a2ee",
   "metadata": {
    "id": "1690a2ee",
    "outputId": "cb4a6766-01e5-4fe7-fe4b-17c91d9100f5"
   },
   "outputs": [],
   "source": [
    "pop_2 = pump_train.loc[(pump_train.population > 1)] \n",
    "pop_list_2 = pop_2.population.values.tolist()\n",
    "print('The number of data entries we have after removing 0s and 1s is: ' + str(len(pop_list_2)))\n",
    "print('The mode of population after removing 0s and 1s is: ' + str(statistics.mode(pop_list_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa103eb3",
   "metadata": {
    "id": "aa103eb3",
    "outputId": "0a332177-b4b4-41d9-be3f-095c193081b1"
   },
   "outputs": [],
   "source": [
    "pop_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a603f5b",
   "metadata": {
    "id": "2a603f5b",
    "outputId": "2b116dec-adfd-421a-9f76-4b48494dbc4a"
   },
   "outputs": [],
   "source": [
    "# Now let us remove data entries whose population score is 3 standard deviations above the mean, where the mean and standard\n",
    "# deviation are calculated after removing 0s and 1s. \n",
    "\n",
    "pop_3 = pump_train.loc[(pump_train.population > 1) & (pump_train.population < 2060)] \n",
    "len(pop_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86227ba3",
   "metadata": {
    "id": "86227ba3",
    "outputId": "984dece5-8860-4fc3-b398-49e314c48fc6"
   },
   "outputs": [],
   "source": [
    "pop_bp_3 = sns.boxplot(x=pop_3[\"population\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07ac367",
   "metadata": {
    "id": "c07ac367"
   },
   "source": [
    "To be very sure, the data dictionary does not provide us with enough information to properly interpret the attribute 'population'. Presumably, it refers to either a) the number of people living within an x metre radius of the water point, or else b) the number of people who the water point regularly services. Without any clarity as to this attribute, it is difficult to know whether the above removal of 0s and 1s was justifiable. We will return to this problem in the data preparation phase. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98798305",
   "metadata": {
    "id": "98798305"
   },
   "source": [
    "### Construction Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6881f",
   "metadata": {
    "id": "c0e6881f",
    "outputId": "3ab40ef5-2ca2-45f3-9bba-4722d803d611"
   },
   "outputs": [],
   "source": [
    "cy_0 = pump_train['construction_year'].loc[pump_train['construction_year'] == 0]\n",
    "print('Our data set contains ' + str(len(cy_0)) + ' data entries with a 0 value for construction year.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efecc6a3",
   "metadata": {
    "id": "efecc6a3"
   },
   "source": [
    "After we remove 0s from our data set we get the following data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a101cc38",
   "metadata": {
    "id": "a101cc38",
    "outputId": "e9aa3542-e361-4d08-809a-52421153cd99"
   },
   "outputs": [],
   "source": [
    "pump_train['construction_year'].loc[pump_train['construction_year'] != 0].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2b9d9b",
   "metadata": {
    "id": "2a2b9d9b"
   },
   "source": [
    "The vast majority of waterpoints were built in the last 30 years, with the oldest water points extending back to the 1960's. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb40cf0",
   "metadata": {
    "id": "ceb40cf0"
   },
   "source": [
    "### GPS Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd46deed",
   "metadata": {
    "id": "dd46deed",
    "outputId": "665009ad-732b-4dfc-e55e-a3f666441f53"
   },
   "outputs": [],
   "source": [
    "pump_train['gps_height'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f979758f",
   "metadata": {
    "id": "f979758f",
    "outputId": "656e453d-2046-448c-a0af-dc89fa13c1a0"
   },
   "outputs": [],
   "source": [
    "Image(filename='topografic_map.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8627a3",
   "metadata": {
    "id": "1a8627a3"
   },
   "source": [
    "Based on this representation you can see that apart from places by the sea there are no places in Tanzania that are below 100m above sea level. Thus, the values ​​0 in the GPS altitude do not count and can be classified as missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f11854",
   "metadata": {
    "id": "90f11854"
   },
   "source": [
    "## Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91ea1e",
   "metadata": {
    "id": "4f91ea1e",
    "outputId": "578e937a-8b06-4f04-88a6-0a9dc8c5ee6d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "collected_cols = []\n",
    "for col in pump_train.columns:\n",
    "    \n",
    "    if pump_train[col].nunique() < 20:\n",
    "        collected_cols.append(col)\n",
    "\n",
    "        \n",
    "\n",
    "a = len(collected_cols)\n",
    "b = 2\n",
    "c = 1  \n",
    "\n",
    "fig = plt.figure(figsize=(12,len(collected_cols)*6))\n",
    "\n",
    "for i, col in enumerate(collected_cols):\n",
    "    plt.subplot(a, b, c)\n",
    "    plt.title(col)\n",
    "    plt.xlabel(i)\n",
    "    pump_train[col].value_counts().plot(kind='bar')\n",
    "    c = c + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a000e7",
   "metadata": {
    "id": "39a000e7"
   },
   "source": [
    "There are several insights to be gained from the above graphs. \n",
    "\n",
    "1. Many of the attributes are replicated. There is, for example, a pair of attributes called 'payment' and 'payment_type'. In the graphs above we see that they have exactly the same values as one another. In other instances, for example, the pair of attributes 'water_quality' and 'quality_group' the graphs are identical except that 'water_quality' has one additional category with what appears to be no or else extremely few values. In still other instances, for example, 'source' and 'source_type', there is enough of differnce for that difference to be relevant. In the data preparation phase we will need to take this into consideration. \n",
    "\n",
    "2. All of the data was recorded by the same company, namely, GeoData Consultants Ltd. We can accordingly drop this attribute as it provides us with no means of differentiating our data. \n",
    "\n",
    "3. There appears to be a discrepancy between the numerical attribute 'amount_tsh' (i.e., amount of water) and the categorical attributes 'quantity' and 'quantity_group'. We will need to look at this relationship more closely in the sequel. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa89b3",
   "metadata": {
    "id": "69fa89b3"
   },
   "source": [
    "## Target feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b755e5d4",
   "metadata": {
    "id": "b755e5d4"
   },
   "source": [
    "We will start by calling up totals for each of the status_group variables. Then we will visualise them as percentages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b39e44a",
   "metadata": {
    "id": "8b39e44a",
    "outputId": "9dae7d16-81c3-4e1f-d4bb-ec588d7ae955"
   },
   "outputs": [],
   "source": [
    "print(pump_train['status_group'].value_counts()) \n",
    "\n",
    "pump_train['status_group'].value_counts(normalize=True).plot(kind=\"bar\", alpha = 0.5)\n",
    "plt.title('Water point status totals in %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be860f3e",
   "metadata": {
    "id": "be860f3e"
   },
   "source": [
    "Just over half of our water points are fully functional, the rest are either non-functional or else require repairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409484ce",
   "metadata": {
    "id": "409484ce"
   },
   "source": [
    "### Correlation with construction year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a1dd3d",
   "metadata": {
    "id": "53a1dd3d",
    "outputId": "fdffa7b0-0eeb-465c-dcd6-bb0e4ab53556"
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(pump_train[pump_train['construction_year'] != 0], hue='status_group', height=6)\n",
    "g.map(sns.histplot,'construction_year',edgecolor=\"w\").add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c2c66c",
   "metadata": {},
   "source": [
    "In this plot you can see the correlation with the construction year. It can be seen that the number of wells built increases as the years go by. In addition, one can see that the non-functioning wells in the years 1960 to 1990 are relatively higher than the following ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8b41f6",
   "metadata": {
    "id": "1b8b41f6"
   },
   "source": [
    "### Correlation with amount_tsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9de7f",
   "metadata": {
    "id": "8ee9de7f",
    "outputId": "31c451a6-1748-46ef-9547-e90f5b70e2c6"
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(pump_train[pump_train['amount_tsh'] == 0], hue='status_group', height=5)\n",
    "g.map(sns.histplot,'amount_tsh',edgecolor=\"w\", bins=1).add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a91cf7",
   "metadata": {
    "id": "24a91cf7",
    "outputId": "2221b06b-62cc-4e22-f7cb-0463ff940516"
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(pump_train[pump_train['amount_tsh'] != 0], hue='status_group', height=5)\n",
    "g.map(sns.histplot,'amount_tsh',edgecolor=\"w\", bins=1).add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9935a2c1",
   "metadata": {},
   "source": [
    "Two plots related to the target variable are presented here. It turns out that when the value is 0, the functionality is higher, but the majority of these fountains still work. For all other non-zero values, you can see that most of these work. So this could be a deciding factor for the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8939c73d",
   "metadata": {
    "id": "8939c73d"
   },
   "source": [
    "### Correlation with gps_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16dbcd9",
   "metadata": {
    "id": "f16dbcd9",
    "outputId": "7f6857cd-2591-4ee0-fb76-9afc0382957a"
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(pump_train[pump_train['gps_height'] != 0], hue='status_group', height=6)\n",
    "g.map(sns.histplot,'gps_height',edgecolor=\"w\").add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6c8bca",
   "metadata": {},
   "source": [
    "In the following plot, the gps height is shown correlated with the target variable. The values ​​0 are excluded for the time being. Here you can see that the functionality is slightly reduced for smaller numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004f2d8",
   "metadata": {
    "id": "3004f2d8"
   },
   "source": [
    "### Correlation with other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1188b28",
   "metadata": {
    "id": "a1188b28",
    "outputId": "f35ddb48-3754-4d27-8764-abc3ae3f12d6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "collected_cols = []\n",
    "for col in pump_train.columns:\n",
    "    \n",
    "    if (pump_train[col].nunique() < 20) and (pump_train[col].nunique() != 2) and col != 'status_group':\n",
    "        collected_cols.append(col)\n",
    "print(collected_cols)\n",
    "        \n",
    "    \n",
    "sns.set(font_scale=0.8)\n",
    "\n",
    "for i, col in enumerate(collected_cols):\n",
    "    plt.figure(i)\n",
    "    g = sns.FacetGrid(pump_train, hue='status_group', height=7)\n",
    "    g.map(sns.histplot,col,edgecolor=\"w\").add_legend()\n",
    "    \n",
    "\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c65f28",
   "metadata": {},
   "source": [
    "In the plots shown here, further features are correlated with the target variable. Many connections can be discovered that could later be important for the models\n",
    "\n",
    "---\n",
    "\n",
    "In order to get a geographical overview of the data, the individual wells are shown on a map in the following illustrations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de00ae",
   "metadata": {
    "id": "d0de00ae",
    "outputId": "473da4b0-4ac2-4459-d548-efea8f51ec82"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(pump_train, lat=\"latitude\", lon=\"longitude\", hover_name=\"id\", hover_data=[\"waterpoint_type\", \"gps_height\", \"status_group\"], zoom=3, height=400, color='status_group')\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb676ade",
   "metadata": {
    "id": "eb676ade",
    "outputId": "c2b9fb8d-a02c-41df-cf78-afe859fef0a3"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(pump_train, lat=\"latitude\", lon=\"longitude\", hover_name=\"id\", hover_data=[\"waterpoint_type\", \"gps_height\", \"status_group\"], zoom=3, height=400, color='status_group')\n",
    "fig.update_layout(\n",
    "    mapbox_layers=[\n",
    "        {\n",
    "            \"below\": 'traces',\n",
    "            \"sourcetype\": \"raster\",\n",
    "            \"sourceattribution\": \"United States Geological Survey\",\n",
    "            \"source\": [\n",
    "                \"https://basemap.nationalmap.gov/arcgis/rest/services/USGSImageryOnly/MapServer/tile/{z}/{y}/{x}\"\n",
    "            ]\n",
    "        }\n",
    "      ],\n",
    "    mapbox_style=\"white-bg\"\n",
    "    \n",
    ")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4650ffd",
   "metadata": {},
   "source": [
    "On the one hand, these maps show that the wells can be found in Tanzania. You can also interact with the map. The fountains differ in color depending on the functional status they have. When hovering over the individual fountains, additional data can also be seen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325ae256",
   "metadata": {
    "id": "325ae256"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb62b6b",
   "metadata": {
    "id": "5cb62b6b"
   },
   "source": [
    "### Cleaning Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d38735",
   "metadata": {},
   "source": [
    "As discussed in the analysis, some numeric values ​​were impure because they contained 0 values, which should be considered as missing values. In order to clean up these features, all 0 values ​​for the feature construction_year and gps_height were replaced by NaN, which should be filled in again later. The amount_tsh feature was done in a similar way. However, only the 0 values ​​that do not have the dry attribute in the qunatity_group column were replaced here. This means that probably dry wells should no longer hold water and should remain at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a333cf",
   "metadata": {
    "id": "a9a333cf",
    "outputId": "ea226ae3-801f-446a-8fd3-20ae71cbf430"
   },
   "outputs": [],
   "source": [
    "pump_train['construction_year'] = pump_train['construction_year'].replace(0, np.NaN)\n",
    "pump_test['construction_year'] = pump_test['construction_year'].replace(0, np.NaN)\n",
    "\n",
    "pump_train.loc[(pump_train.quantity_group != 'dry') & (pump_train.amount_tsh == 0), 'amount_tsh'] = pump_train.loc[(pump_train.quantity_group != 'dry') & (pump_train.amount_tsh == 0), 'amount_tsh'].replace(0, np.NaN)\n",
    "pump_test.loc[(pump_test.quantity_group != 'dry') & (pump_test.amount_tsh == 0), 'amount_tsh'] = pump_test.loc[(pump_test.quantity_group != 'dry') & (pump_test.amount_tsh == 0), 'amount_tsh'] .replace(0, np.NaN)\n",
    "\n",
    "pump_train['gps_height'] = pump_train['gps_height'].replace(0, np.NaN)\n",
    "pump_test['gps_height'] = pump_test['gps_height'].replace(0, np.NaN)\n",
    "\n",
    "print(pump_train['construction_year'].isnull().sum())\n",
    "print(pump_train['gps_height'].isnull().sum())\n",
    "\n",
    "pump_train.isnull().sum()\n",
    "pump_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0369aa",
   "metadata": {
    "id": "ae0369aa"
   },
   "source": [
    "### Preparing Data for Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3add688b",
   "metadata": {},
   "source": [
    "In order to prepare the values ​​for the model, the feature groups should first be summarized. First, features are determined which should be removed from the data set, as they do not add any value. After that, all numerical features are summarized and prepared for further processing. In addition, columns are grouped for a custom transform. Finally, the remaining columns for the label encoding and the onehot encoding are split. This is determined using the unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8154f8",
   "metadata": {
    "id": "ae8154f8"
   },
   "outputs": [],
   "source": [
    "features_drop = [\"id\",\n",
    "                 \"scheme_name\",\n",
    "                  \"num_private\"\n",
    "                ]\n",
    "\n",
    "features_scale = pump_train.loc[:,~pump_train.columns.isin(features_drop)].select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns\n",
    "\n",
    "features_custom = [\"public_meeting\",\"permit\"]\n",
    "\n",
    "label_cols = []\n",
    "onehot_cols = []\n",
    "for col in pump_train.columns[~pump_train.columns.isin(features_scale) & ~pump_train.columns.isin(features_drop) & ~pump_train.columns.isin(features_custom)]:\n",
    "    \n",
    "    if pump_train[col].nunique() <= 5:\n",
    "        onehot_cols.append(col)\n",
    "    else:\n",
    "        label_cols.append(col)\n",
    "\n",
    "\n",
    "features_label_encode = label_cols\n",
    "features_onehot_encode = onehot_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b9e6d8",
   "metadata": {
    "id": "44b9e6d8"
   },
   "source": [
    "### Drop features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c8a40e",
   "metadata": {},
   "source": [
    "Here the desired columns are removed in the training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359f14f7",
   "metadata": {
    "id": "359f14f7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pump_train = pump_train.drop(columns=features_drop)\n",
    "pump_test = pump_test.drop(columns=features_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c5152a",
   "metadata": {
    "id": "13c5152a"
   },
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99225634",
   "metadata": {},
   "source": [
    "Here the specified columns are label encoded in the training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b09fc",
   "metadata": {
    "id": "c99b09fc"
   },
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "\n",
    "pump_train[features_label_encode] = pump_train[features_label_encode].apply(labelencoder.fit_transform)\n",
    "pump_test[features_label_encode] = pump_test[features_label_encode].apply(labelencoder.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded53f8d",
   "metadata": {
    "id": "ded53f8d"
   },
   "source": [
    "### OneHot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09526d5",
   "metadata": {},
   "source": [
    "Here the specified columns are label encoded in the training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f76dee",
   "metadata": {
    "id": "96f76dee"
   },
   "outputs": [],
   "source": [
    "one_hot_train = pd.get_dummies(pump_train, columns = features_onehot_encode)\n",
    "one_hot_test = pd.get_dummies(pump_test, columns = features_onehot_encode)\n",
    "\n",
    "pump_train = pump_train.drop(features_onehot_encode,axis = 1)\n",
    "pump_test = pump_test.drop(features_onehot_encode,axis = 1)\n",
    "\n",
    "pump_train = pump_train.merge(one_hot_train)\n",
    "pump_test = pump_test.merge(one_hot_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f50d1",
   "metadata": {
    "id": "9d9f50d1"
   },
   "source": [
    "### Filling NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aca8557",
   "metadata": {},
   "source": [
    "Two functions were written to fill in missing values. These enable categorical values ​​as well as numerical values ​​to be predicted by models in order to achieve the best possible data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e0f21a",
   "metadata": {
    "id": "94e0f21a"
   },
   "outputs": [],
   "source": [
    "def fill_missing_values_cat(df, target_column, drop_columns):\n",
    "    \n",
    "    train = df[df[target_column].notnull()]\n",
    "    test = df[df[target_column].isnull()]\n",
    "    \n",
    "    train = train.drop(columns=drop_columns)\n",
    "    test = test.drop(columns=drop_columns)\n",
    "    \n",
    "    x = train.drop(columns=target_column)\n",
    "    y = train[target_column]\n",
    "    \n",
    "    etc = ExtraTreesClassifier(n_jobs=-1)\n",
    "    etc.fit(x, y)\n",
    "    y_pred = etc.predict(test.drop(columns=target_column))\n",
    "\n",
    "    df.loc[(df[target_column].isnull()), target_column ] = y_pred\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fill_missing_values_reg(df, target_column, drop_columns):\n",
    "    \n",
    "    train = df[df[target_column].notnull()]\n",
    "    test = df[df[target_column].isnull()]\n",
    "    \n",
    "    train = train.drop(columns=drop_columns)\n",
    "    test = test.drop(columns=drop_columns)\n",
    "    \n",
    "    x = train.drop(columns=target_column)\n",
    "    y = train[target_column]\n",
    "    \n",
    "    rtr = RandomForestRegressor(n_jobs=-1)\n",
    "    rtr.fit(x, y)\n",
    "    y_pred = rtr.predict(test.drop(columns=target_column))\n",
    "\n",
    "    df.loc[(df[target_column].isnull()), target_column ] = y_pred\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c270fb0b",
   "metadata": {},
   "source": [
    "The missing values ​​are now replaced in the following paragraph. For the first three features, only 'Missing' is initially entered as a value, since these contain many names and a prediction here is not productive. For the following features 'construction_year', 'gps_height', 'amount_tsh', 'permit' and 'public_meeting' the values ​​are populated by machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d7fd35",
   "metadata": {
    "id": "54d7fd35"
   },
   "outputs": [],
   "source": [
    "# Funder\n",
    "pump_train['funder'] = pump_train['funder'].fillna('Missing')\n",
    "pump_test['funder'] = pump_test['funder'].fillna('Missing')\n",
    "\n",
    "# Installer\n",
    "pump_train['installer'] = pump_train['installer'].fillna('Missing')\n",
    "pump_test['installer'] = pump_test['installer'].fillna('Missing')\n",
    "\n",
    "# Subvillage\n",
    "pump_train['subvillage'] = pump_train['subvillage'].fillna('Missing')\n",
    "pump_test['subvillage'] = pump_test['subvillage'].fillna('Missing')\n",
    "\n",
    "# scheme_management\n",
    "pump_train['scheme_management'] = pump_train['scheme_management'].fillna('Missing')\n",
    "pump_test['scheme_management'] = pump_test['scheme_management'].fillna('Missing')\n",
    "\n",
    "# Construction year\n",
    "pump_train = fill_missing_values_reg(pump_train, 'construction_year', ['permit', 'public_meeting','gps_height','amount_tsh'])\n",
    "pump_test = fill_missing_values_reg(pump_test, 'construction_year', ['permit', 'public_meeting','gps_height','amount_tsh'])\n",
    "\n",
    "# Amount tsh\n",
    "pump_train = fill_missing_values_reg(pump_train, 'amount_tsh', ['permit', 'public_meeting','gps_height'])\n",
    "pump_test = fill_missing_values_reg(pump_test, 'amount_tsh', ['permit', 'public_meeting','gps_height'])\n",
    "\n",
    "# GPS height\n",
    "pump_train = fill_missing_values_reg(pump_train, 'gps_height', ['permit', 'public_meeting'])\n",
    "pump_test = fill_missing_values_reg(pump_test, 'gps_height', ['permit', 'public_meeting'])\n",
    "\n",
    "# Public meeting (could be predicted)\n",
    "pump_train['public_meeting'] = pump_train['public_meeting'].replace({True: 1, False: 0})\n",
    "pump_test['public_meeting'] = pump_test['public_meeting'].replace({True: 1, False: 0})\n",
    "\n",
    "pump_train = fill_missing_values_cat(pump_train, 'public_meeting', 'permit')\n",
    "pump_test = fill_missing_values_cat(pump_test, 'public_meeting', 'permit')\n",
    "\n",
    "# Permit (could be predicted)\n",
    "pump_train['permit'] = pump_train['permit'].replace({True: 1, False: 0})\n",
    "pump_test['permit'] = pump_test['permit'].replace({True: 1, False: 0})\n",
    "\n",
    "pump_train = fill_missing_values_cat(pump_train, 'permit', 'public_meeting')\n",
    "pump_test = fill_missing_values_cat(pump_test, 'permit', 'public_meeting')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3746c27",
   "metadata": {
    "id": "c3746c27",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pump_train.isnull().sum()\n",
    "# pump_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc84957",
   "metadata": {
    "id": "fbc84957"
   },
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8513892a",
   "metadata": {
    "id": "8513892a"
   },
   "outputs": [],
   "source": [
    "scaler_train = StandardScaler()\n",
    "scaler_test = StandardScaler()\n",
    "# transform data\n",
    "pump_train[features_scale] = scaler_train.fit_transform(pump_train[features_scale])\n",
    "pump_test[features_scale] = scaler_train.transform(pump_test[features_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19e5741",
   "metadata": {
    "id": "d19e5741"
   },
   "source": [
    "\n",
    "# Model: functioning or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d4386f",
   "metadata": {},
   "source": [
    "The first model to be created has the purpose of predicting whether the well is functional or not. This is implemented using a wide variety of models and the results are then assessed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c8bb2b",
   "metadata": {
    "id": "09c8bb2b"
   },
   "source": [
    "\n",
    "## Model specific adjustements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0bc28",
   "metadata": {
    "id": "01e0bc28"
   },
   "outputs": [],
   "source": [
    "target_feature = 'status_group_non functional'\n",
    "\n",
    "m1_pump_train = pump_train.copy()\n",
    "m1_pump_train = m1_pump_train.drop(columns=['status_group_functional','status_group_functional needs repair'])\n",
    "m1_pump_test = pump_test.copy()\n",
    "m1_pump_test = m1_pump_test.drop(columns=['status_group_functional','status_group_functional needs repair'])\n",
    "\n",
    "\n",
    "x_train = m1_pump_train.drop(columns=target_feature)\n",
    "y_train = m1_pump_train[target_feature]\n",
    "x_val = m1_pump_test.drop(columns=target_feature)\n",
    "y_val = m1_pump_test[target_feature]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8a288c",
   "metadata": {
    "id": "0e8a288c"
   },
   "source": [
    "## ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d82131d",
   "metadata": {
    "id": "0d82131d"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eda16f",
   "metadata": {
    "id": "d3eda16f"
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=3000, n_jobs=-1)\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred_logreg = logreg.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc48bd45",
   "metadata": {
    "id": "fc48bd45"
   },
   "source": [
    "### Gaussian Naive Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87db02",
   "metadata": {
    "id": "3b87db02"
   },
   "outputs": [],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(x_train, y_train)\n",
    "y_pred_gaussian = gaussian.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164fd708",
   "metadata": {
    "id": "164fd708"
   },
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3147e93",
   "metadata": {
    "id": "b3147e93"
   },
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(n_jobs=-1)\n",
    "randomforest.fit(x_train, y_train)\n",
    "y_pred_randomforest = randomforest.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba4e310",
   "metadata": {
    "id": "dba4e310"
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43636fa",
   "metadata": {
    "id": "b43636fa"
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_jobs=-1)\n",
    "xgb.fit(x_train, y_train)\n",
    "y_pred_xgb = xgb.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc35e3f4",
   "metadata": {
    "id": "cc35e3f4"
   },
   "source": [
    "### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac87867",
   "metadata": {
    "id": "fac87867"
   },
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(n_jobs=-1)\n",
    "etc.fit(x_train, y_train)\n",
    "y_pred_etc = etc.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a1b2d3",
   "metadata": {
    "id": "34a1b2d3"
   },
   "source": [
    "### Hyperparametertuning - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f8327",
   "metadata": {
    "id": "c34f8327"
   },
   "outputs": [],
   "source": [
    "iterations = 50\n",
    "folds = 3\n",
    "cpu_cores = -1\n",
    "\n",
    "rfc_tuned = RandomForestClassifier(n_jobs=-1)\n",
    "params = {\n",
    " 'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "}\n",
    "\n",
    "rfc_tuned_RSCV = RandomizedSearchCV(rfc_tuned, param_distributions=params, random_state=42, n_iter=iterations, cv=folds, verbose=2, n_jobs=cpu_cores, return_train_score=True)\n",
    "rfc_tuned_RSCV.fit(x_train, y_train)\n",
    "\n",
    "print(rfc_tuned_RSCV.best_estimator_.get_params())\n",
    "\n",
    "y_pred_rfc_tuned = rfc_tuned_RSCV.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40800a39",
   "metadata": {
    "id": "40800a39"
   },
   "source": [
    "### Hyperparametertuning - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ca2420",
   "metadata": {
    "id": "15ca2420"
   },
   "outputs": [],
   "source": [
    "\n",
    "# RandomSearchCV XGBoost\n",
    "iterations = 50\n",
    "folds = 3\n",
    "cpu_cores = -1\n",
    "\n",
    "xgb_tuned = XGBClassifier(n_jobs=-1)\n",
    "params = {\n",
    "    \"learning_rate\" : [0.05,0.10,0.15,0.20,0.25,0.30],\n",
    "    \"max_depth\" : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "    \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "    \"gamma\": [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "    \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "}\n",
    "\n",
    "xgb_tuned_RSCV = RandomizedSearchCV(xgb_tuned, param_distributions=params, random_state=42, n_iter=iterations, cv=folds, verbose=2, n_jobs=cpu_cores, return_train_score=True)\n",
    "xgb_tuned_RSCV.fit(x_train, y_train)\n",
    "\n",
    "print(xgb_tuned_RSCV.best_estimator_.get_params())\n",
    "\n",
    "y_pred_xgb_tuned = xgb_tuned_RSCV.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e4adfa",
   "metadata": {
    "id": "c0e4adfa"
   },
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab94d5e",
   "metadata": {
    "id": "8ab94d5e"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Voting Classifier\n",
    "estimators = []\n",
    "\n",
    "\n",
    "estimators.append(('randomforest', randomforest))\n",
    "estimators.append(('xgb', xgb))\n",
    "estimators.append(('etc', etc))\n",
    "\n",
    "ensemble = VotingClassifier(estimators, voting='soft')\n",
    "ensemble.fit(x_train, y_train)\n",
    "y_pred_voting = ensemble.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e7003a",
   "metadata": {
    "id": "f8e7003a"
   },
   "source": [
    "\n",
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad65078",
   "metadata": {
    "id": "dad65078",
    "outputId": "ca27754d-47b6-4679-f8d4-19833f419a98"
   },
   "outputs": [],
   "source": [
    "print('Logistic Regression: \\n' + str(metrics.roc_auc_score(y_val, y_pred_logreg[:,1])))\n",
    "print('Gaussian Naive Bias: \\n' + str(metrics.roc_auc_score(y_val, y_pred_gaussian[:,1])))\n",
    "print('Random Forest Classifier: \\n' + str(metrics.roc_auc_score(y_val, y_pred_randomforest[:,1])))\n",
    "print('XGBoost: \\n' + str(metrics.roc_auc_score(y_val, y_pred_xgb[:,1])))\n",
    "print('ExtraTreeClassifier: \\n' + str(metrics.roc_auc_score(y_val, y_pred_etc[:,1])))\n",
    "print('Random Forest Classifier with tuning: \\n' + str(metrics.roc_auc_score(y_val, y_pred_rfc_tuned[:,1])))\n",
    "print('XGBoost with tuning: \\n' + str(metrics.roc_auc_score(y_val, y_pred_xgb_tuned[:,1])))\n",
    "print('VotingClassifier: \\n' + str(metrics.roc_auc_score(y_val, y_pred_voting[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec70a876",
   "metadata": {
    "id": "ec70a876"
   },
   "source": [
    "# Model: Needs repairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3959ad2",
   "metadata": {},
   "source": [
    "The second model to be created has the purpose of predicting whether the well is needs to be repaired or not. This is also implemented using a wide variety of models and the results are then assessed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53353ef",
   "metadata": {
    "id": "a53353ef"
   },
   "source": [
    "## Model specific adjustements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c1afc",
   "metadata": {
    "id": "527c1afc"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "target_feature = 'status_group_functional needs repair'\n",
    "\n",
    "m2_pump_train = pump_train.copy()\n",
    "m2_pump_train = m2_pump_train.drop(columns=['status_group_functional','status_group_non functional'])\n",
    "m2_pump_test = pump_test.copy()\n",
    "m2_pump_test = m2_pump_test.drop(columns=['status_group_functional','status_group_non functional'])\n",
    "\n",
    "\n",
    "x_train = m2_pump_train.drop(columns=target_feature)\n",
    "y_train = m2_pump_train[target_feature]\n",
    "x_val = m2_pump_test.drop(columns=target_feature)\n",
    "y_val = m2_pump_test[target_feature]\n",
    "\n",
    "\n",
    "rus = RandomUnderSampler() \n",
    "\n",
    "x_train, y_train = rus.fit_resample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66603aac",
   "metadata": {
    "id": "66603aac"
   },
   "source": [
    "## ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a49db3e",
   "metadata": {
    "id": "7a49db3e"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46323ff5",
   "metadata": {
    "id": "46323ff5"
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=3000, n_jobs=-1)\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred_logreg = logreg.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68606ee7",
   "metadata": {
    "id": "68606ee7"
   },
   "source": [
    "### Gaussian Naive Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae9500",
   "metadata": {
    "id": "b2ae9500"
   },
   "outputs": [],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(x_train, y_train)\n",
    "y_pred_gaussian = gaussian.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46ff6e2",
   "metadata": {
    "id": "f46ff6e2"
   },
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db904d2",
   "metadata": {
    "id": "7db904d2"
   },
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(n_jobs=-1)\n",
    "randomforest.fit(x_train, y_train)\n",
    "y_pred_randomforest = randomforest.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64726200",
   "metadata": {
    "id": "64726200"
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d30f8",
   "metadata": {
    "id": "130d30f8"
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_jobs=-1)\n",
    "xgb.fit(x_train, y_train)\n",
    "y_pred_xgb = xgb.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554a620b",
   "metadata": {
    "id": "554a620b"
   },
   "source": [
    "### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9834e0eb",
   "metadata": {
    "id": "9834e0eb"
   },
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(n_jobs=-1)\n",
    "etc.fit(x_train, y_train)\n",
    "y_pred_etc = etc.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f3c5fb",
   "metadata": {
    "id": "09f3c5fb"
   },
   "source": [
    "### Hyperparametertuning - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c37217",
   "metadata": {
    "id": "75c37217"
   },
   "outputs": [],
   "source": [
    "iterations = 50\n",
    "folds = 3\n",
    "cpu_cores = -1\n",
    "\n",
    "rfc_tuned = RandomForestClassifier(n_jobs=-1)\n",
    "params = {\n",
    " 'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "}\n",
    "\n",
    "rfc_tuned_RSCV = RandomizedSearchCV(rfc_tuned, param_distributions=params, random_state=42, n_iter=iterations, cv=folds, verbose=2, n_jobs=cpu_cores, return_train_score=True)\n",
    "rfc_tuned_RSCV.fit(x_train, y_train)\n",
    "\n",
    "print(rfc_tuned_RSCV.best_estimator_.get_params())\n",
    "\n",
    "y_pred_rfc_tuned = rfc_tuned_RSCV.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c5c4ff",
   "metadata": {
    "id": "a6c5c4ff"
   },
   "source": [
    "### Hyperparametertuning - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe13397",
   "metadata": {
    "id": "cfe13397"
   },
   "outputs": [],
   "source": [
    "\n",
    "# RandomSearchCV XGBoost\n",
    "iterations = 50\n",
    "folds = 3\n",
    "cpu_cores = -1\n",
    "\n",
    "xgb_tuned = XGBClassifier(n_jobs=-1)\n",
    "params = {\n",
    "    \"learning_rate\" : [0.05,0.10,0.15,0.20,0.25,0.30],\n",
    "    \"max_depth\" : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "    \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "    \"gamma\": [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "    \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "}\n",
    "\n",
    "xgb_tuned_RSCV = RandomizedSearchCV(xgb_tuned, param_distributions=params, random_state=42, n_iter=iterations, cv=folds, verbose=2, n_jobs=cpu_cores, return_train_score=True)\n",
    "xgb_tuned_RSCV.fit(x_train, y_train)\n",
    "\n",
    "print(xgb_tuned_RSCV.best_estimator_.get_params())\n",
    "\n",
    "y_pred_xgb_tuned = xgb_tuned_RSCV.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a899781",
   "metadata": {
    "id": "9a899781"
   },
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc64a64",
   "metadata": {
    "id": "5dc64a64"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Voting Classifier\n",
    "estimators = []\n",
    "\n",
    "\n",
    "estimators.append(('randomforest', randomforest))\n",
    "estimators.append(('xgb', xgb))\n",
    "estimators.append(('etc', etc))\n",
    "\n",
    "ensemble = VotingClassifier(estimators, voting='soft')\n",
    "ensemble.fit(x_train, y_train)\n",
    "y_pred_voting = ensemble.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd97841",
   "metadata": {
    "id": "2bd97841"
   },
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd655956",
   "metadata": {
    "id": "cd655956",
    "outputId": "c6c031dd-bed5-4d63-d5b9-054643cbad64"
   },
   "outputs": [],
   "source": [
    "print('Logistic Regression: \\n' + str(metrics.roc_auc_score(y_val, y_pred_logreg[:,1])))\n",
    "print('Gaussian Naive Bias: \\n' + str(metrics.roc_auc_score(y_val, y_pred_gaussian[:,1])))\n",
    "print('Random Forest Classifier: \\n' + str(metrics.roc_auc_score(y_val, y_pred_randomforest[:,1])))\n",
    "print('XGBoost: \\n' + str(metrics.roc_auc_score(y_val, y_pred_xgb[:,1])))\n",
    "print('ExtraTreeClassifier: \\n' + str(metrics.roc_auc_score(y_val, y_pred_etc[:,1])))\n",
    "print('Random Forest Classifier with tuning: \\n' + str(metrics.roc_auc_score(y_val, y_pred_rfc_tuned[:,1])))\n",
    "print('XGBoost with tuning: \\n' + str(metrics.roc_auc_score(y_val, y_pred_xgb_tuned[:,1])))\n",
    "print('VotingClassifier: \\n' + str(metrics.roc_auc_score(y_val, y_pred_voting[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bb43d5",
   "metadata": {
    "id": "e7bb43d5"
   },
   "source": [
    "# Model 3: All 3 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083e3701",
   "metadata": {},
   "source": [
    "The third model to be created has the purpose of predicting all three classes the status column offers. This is also implemented using a wide variety of models and the results are then assessed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286a006f",
   "metadata": {
    "id": "286a006f"
   },
   "source": [
    "## Model specific adjustements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d926f520",
   "metadata": {
    "id": "d926f520"
   },
   "outputs": [],
   "source": [
    "target_feature = 'status'\n",
    "\n",
    "m3_pump_train = pump_train.copy()\n",
    "\n",
    "temp = []\n",
    "for index, row in m3_pump_train.iterrows():\n",
    "\n",
    "    if row['status_group_functional'] == 1:\n",
    "        temp.append(0)\n",
    "    elif row['status_group_non functional'] == 1:\n",
    "        temp.append(1)\n",
    "    elif row['status_group_functional needs repair'] == 1:\n",
    "        temp.append(2)\n",
    "\n",
    "m3_pump_train['status'] = temp\n",
    "m3_pump_train = m3_pump_train.drop(columns=['status_group_functional','status_group_non functional','status_group_functional needs repair'])\n",
    "\n",
    "\n",
    "m3_pump_test = pump_test.copy()\n",
    "\n",
    "temp = []\n",
    "for index, row in m3_pump_test.iterrows():\n",
    "    if row['status_group_functional'] == 1:\n",
    "        temp.append(0)\n",
    "    elif row['status_group_non functional'] == 1:\n",
    "        temp.append(1)\n",
    "    elif row['status_group_functional needs repair'] == 1:\n",
    "        temp.append(2)\n",
    "\n",
    "m3_pump_test['status'] = temp\n",
    "m3_pump_test = m3_pump_test.drop(columns=['status_group_functional','status_group_non functional','status_group_functional needs repair'])\n",
    "\n",
    "\n",
    "x_train = m3_pump_train.drop(columns=target_feature)\n",
    "y_train = m3_pump_train[target_feature]\n",
    "x_val = m3_pump_test.drop(columns=target_feature)\n",
    "y_val = m3_pump_test[target_feature]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154d3e13",
   "metadata": {
    "id": "154d3e13"
   },
   "source": [
    "## ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df846098",
   "metadata": {
    "id": "df846098"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207f817",
   "metadata": {
    "id": "d207f817"
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=3000, n_jobs=-1)\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred_logreg = logreg.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e130a2",
   "metadata": {
    "id": "71e130a2"
   },
   "source": [
    "### Gaussian Naive Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd5428",
   "metadata": {
    "id": "e3dd5428"
   },
   "outputs": [],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(x_train, y_train)\n",
    "y_pred_gaussian = gaussian.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cac541",
   "metadata": {
    "id": "20cac541"
   },
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec645c5",
   "metadata": {
    "id": "4ec645c5"
   },
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(n_jobs=-1)\n",
    "randomforest.fit(x_train, y_train)\n",
    "y_pred_randomforest = randomforest.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eab060",
   "metadata": {
    "id": "e2eab060"
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac97468",
   "metadata": {
    "id": "cac97468"
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_jobs=-1)\n",
    "xgb.fit(x_train, y_train)\n",
    "y_pred_xgb = xgb.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a71ba98",
   "metadata": {
    "id": "0a71ba98"
   },
   "source": [
    "### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c27503",
   "metadata": {
    "id": "b4c27503"
   },
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(n_jobs=-1)\n",
    "etc.fit(x_train, y_train)\n",
    "y_pred_etc = etc.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988e6c75",
   "metadata": {
    "id": "988e6c75"
   },
   "source": [
    "### Hyperparametertuning - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940740e8",
   "metadata": {
    "id": "940740e8"
   },
   "outputs": [],
   "source": [
    "iterations = 50\n",
    "folds = 3\n",
    "cpu_cores = -1\n",
    "\n",
    "rfc_tuned = RandomForestClassifier(n_jobs=-1)\n",
    "params = {\n",
    " 'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "}\n",
    "\n",
    "rfc_tuned_RSCV = RandomizedSearchCV(rfc_tuned, param_distributions=params, random_state=42, n_iter=iterations, cv=folds, verbose=2, n_jobs=cpu_cores, return_train_score=True)\n",
    "rfc_tuned_RSCV.fit(x_train, y_train)\n",
    "\n",
    "print(rfc_tuned_RSCV.best_estimator_.get_params())\n",
    "\n",
    "y_pred_rfc_tuned = rfc_tuned_RSCV.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd13a478",
   "metadata": {
    "id": "dd13a478"
   },
   "source": [
    "### Hyperparametertuning - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986c9be4",
   "metadata": {
    "id": "986c9be4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# RandomSearchCV XGBoost\n",
    "iterations = 50\n",
    "folds = 3\n",
    "cpu_cores = -1\n",
    "\n",
    "xgb_tuned = XGBClassifier(n_jobs=-1)\n",
    "params = {\n",
    "    \"learning_rate\" : [0.05,0.10,0.15,0.20,0.25,0.30],\n",
    "    \"max_depth\" : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "    \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "    \"gamma\": [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "    \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "}\n",
    "\n",
    "xgb_tuned_RSCV = RandomizedSearchCV(xgb_tuned, param_distributions=params, random_state=42, n_iter=iterations, cv=folds, verbose=2, n_jobs=cpu_cores, return_train_score=True)\n",
    "xgb_tuned_RSCV.fit(x_train, y_train)\n",
    "\n",
    "print(xgb_tuned_RSCV.best_estimator_.get_params())\n",
    "\n",
    "y_pred_xgb_tuned = xgb_tuned_RSCV.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbf20e1",
   "metadata": {
    "id": "9cbf20e1"
   },
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d231eda6",
   "metadata": {
    "id": "d231eda6"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Voting Classifier\n",
    "estimators = []\n",
    "\n",
    "\n",
    "estimators.append(('randomforest', randomforest))\n",
    "estimators.append(('xgb', xgb))\n",
    "estimators.append(('etc', etc))\n",
    "\n",
    "ensemble = VotingClassifier(estimators, voting='soft')\n",
    "ensemble.fit(x_train, y_train)\n",
    "y_pred_voting = ensemble.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc85f8",
   "metadata": {
    "id": "ffcc85f8"
   },
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb01836d",
   "metadata": {
    "id": "bb01836d",
    "outputId": "96cb8cc3-e4f8-48c3-88a7-66da1581a514"
   },
   "outputs": [],
   "source": [
    "print('Logistic Regression: \\n' + str(metrics.roc_auc_score(y_val, y_pred_logreg, multi_class=\"ovr\", average=\"weighted\")))\n",
    "print('Gaussian Naive Bias: \\n' + str(metrics.roc_auc_score(y_val, y_pred_gaussian, multi_class=\"ovr\", average=\"weighted\")))\n",
    "print('Random Forest Classifier: \\n' + str(metrics.roc_auc_score(y_val, y_pred_randomforest, multi_class=\"ovr\", average=\"weighted\")))\n",
    "print('XGBoost: \\n' + str(metrics.roc_auc_score(y_val, y_pred_xgb, multi_class=\"ovr\", average=\"weighted\")))\n",
    "print('ExtraTreeClassifier: \\n' + str(metrics.roc_auc_score(y_val, y_pred_etc, multi_class=\"ovr\", average=\"weighted\")))\n",
    "print('Random Forest Classifier with tuning: \\n' + str(metrics.roc_auc_score(y_val, y_pred_rfc_tuned, multi_class=\"ovr\", average=\"weighted\")))\n",
    "print('XGBoost with tuning: \\n' + str(metrics.roc_auc_score(y_val, y_pred_xgb_tuned, multi_class=\"ovr\", average=\"weighted\")))\n",
    "print('VotingClassifier: \\n' + str(metrics.roc_auc_score(y_val, y_pred_voting, multi_class=\"ovr\", average=\"weighted\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35180f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Notebook_Portfolioaufgabe_V10.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
